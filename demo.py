#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è AI Text Analyzer
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ API
"""

import requests
import json
import time
from typing import List, Dict

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_BASE_URL = "http://localhost:8000"
DEMO_TEXTS = [
    {
        "text": "–≠—Ç–æ –æ—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç! –Ø –æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω –ø–æ–∫—É–ø–∫–æ–π. –†–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Å–µ–º!",
        "description": "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –æ—Ç–∑—ã–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
    },
    {
        "text": "This is a terrible product. I'm very disappointed with the quality.",
        "description": "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–∑—ã–≤ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º"
    },
    {
        "text": "–°–µ–≥–æ–¥–Ω—è –æ–±—ã—á–Ω—ã–π –¥–µ–Ω—å. –ù–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç. –ü–æ–≥–æ–¥–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è.",
        "description": "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç"
    },
    {
        "text": "Machine learning and artificial intelligence are transforming our world. These 
technologies enable computers to learn from data and make intelligent decisions.",
        "description": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç"
    },
    {
        "text": "üéâ –°—É–ø–µ—Ä –Ω–æ–≤–æ—Å—Ç—å! –ù–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞ –≤—ã–∏–≥—Ä–∞–ª–∞ —Ö–∞–∫–∞—Ç–æ–Ω! üèÜ –ú—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –ø–æ—Ç—Ä—è—Å–∞—é—â–∏–π 
AI-–ø—Ä–æ–µ–∫—Ç –∑–∞ 48 —á–∞—Å–æ–≤. –°–ø–∞—Å–∏–±–æ –≤—Å–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–∞–º! üí™‚ú®",
        "description": "–¢–µ–∫—Å—Ç —Å —ç–º–æ–¥–∑–∏ –∏ —Å–ª–µ–Ω–≥–æ–º"
    }
]

def print_header(title: str):
    """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    print(f"\n{'='*60}")
    print(f"üß† {title}")
    print(f"{'='*60}")

def print_analysis_result(result: Dict, description: str):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    print(f"\nüìù {description}")
    print(f"–¢–µ–∫—Å—Ç: {result.get('text', 'N/A')[:100]}...")
    print("-" * 50)
    
    # –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    sentiment = result.get('sentiment', {})
    sentiment_emoji = {
        'positive': 'üòä',
        'negative': 'üòû',
        'neutral': 'üòê'
    }
    print(f"üòä –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment_emoji.get(sentiment.get('label', 'neutral'), 'üòê')} "
          f"{sentiment.get('label', 'unknown')} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {sentiment.get('confidence', 0):.2f})")
    
    # –Ø–∑—ã–∫
    language = result.get('language', {})
    print(f"üåç –Ø–∑—ã–∫: {language.get('language_name', 'Unknown')} "
          f"({language.get('language', 'unknown')}) - {language.get('confidence', 0):.2f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = result.get('statistics', {})
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats.get('word_count', 0)} —Å–ª–æ–≤, "
          f"{stats.get('sentence_count', 0)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, "
          f"—á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å: {stats.get('readability_score', 0):.1f}/100")
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = result.get('keywords', [])
    if keywords:
        top_keywords = [kw['word'] for kw in keywords[:5]]
        print(f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(top_keywords)}")
    
    print(f"‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.get('processing_time_ms', 0):.1f}ms")

def check_api_health() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API"""
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=5)
        return response.status_code == 200
    except requests.exceptions.RequestException:
        return False

def analyze_single_text(text: str, description: str):
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/analyze",
            json={
                "text": text,
                "include_keywords": True,
                "max_keywords": 5
            },
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            result['text'] = text  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            print_analysis_result(result, description)
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {response.status_code} - {response.text}")
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")

def batch_analyze_demo():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    print_header("–ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤")
    
    texts = [item["text"] for item in DEMO_TEXTS[:3]]
    
    try:
        response = requests.post(
            f"{API_BASE_URL}/batch-analyze",
            json=texts,
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {result['processed_count']} —Ç–µ–∫—Å—Ç–æ–≤")
            
            for i, analysis in enumerate(result['results']):
                print(f"\nüìÑ –¢–µ–∫—Å—Ç {i+1}:")
                print(f"   –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {analysis['sentiment']['label']}")
                print(f"   –Ø–∑—ã–∫: {analysis['language']['language_name']}")
                print(f"   –í—Ä–µ–º—è: {analysis['processing_time_ms']:.1f}ms")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {response.status_code}")
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")

def show_api_stats():
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É API"""
    print_header("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API")
    
    try:
        response = requests.get(f"{API_BASE_URL}/stats", timeout=5)
        
        if response.status_code == 200:
            stats = response.json()
            print(f"üìà –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}")
            print(f"üìù –¢–µ–∫—Å—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['total_texts_analyzed']}")
            print(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats['avg_processing_time_ms']:.1f}ms")
            print(f"üåç –ü–æ–ø—É–ª—è—Ä–Ω—ã–π —è–∑—ã–∫: {stats['most_common_language']}")
            print(f"üïê –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {stats['uptime_seconds']:.1f}s")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {response.status_code}")
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")

def performance_test():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print_header("–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    test_text = "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."
    num_requests = 10
    
    print(f"üöÄ –í—ã–ø–æ–ª–Ω—è–µ–º {num_requests} –∑–∞–ø—Ä–æ—Å–æ–≤...")
    
    times = []
    for i in range(num_requests):
        start_time = time.time()
        
        try:
            response = requests.post(
                f"{API_BASE_URL}/analyze",
                json={"text": f"{test_text} –ó–∞–ø—Ä–æ—Å #{i+1}", "include_keywords": False},
                timeout=10
            )
            
            if response.status_code == 200:
                request_time = (time.time() - start_time) * 1000
                times.append(request_time)
                print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: {request_time:.1f}ms")
            else:
                print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: –û—à–∏–±–∫–∞ {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            print(f"   –ó–∞–ø—Ä–æ—Å {i+1}: –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
    
    if times:
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(times)}/{num_requests}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.1f}ms")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min_time:.1f}ms")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_time:.1f}ms")
        print(f"   –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: ~{1000/avg_time*60:.0f} –∑–∞–ø—Ä–æ—Å–æ–≤/–º–∏–Ω—É—Ç—É")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print_header("AI Text Analyzer - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
    print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API...")
    if not check_api_health():
        print("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8000")
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä –∫–æ–º–∞–Ω–¥–æ–π: uvicorn app.main:app --reload")
        return
    
    print("‚úÖ API –¥–æ—Å—Ç—É–ø–Ω–æ!")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
    print_header("–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤")
    
    for item in DEMO_TEXTS:
        analyze_single_text(item["text"], item["description"])
        time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    # –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    batch_analyze_demo()
    
    # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    performance_test()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    show_api_stats()
    
    print_header("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üéâ –°–ø–∞—Å–∏–±–æ –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ –∫ AI Text Analyzer!")
    print("üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    print("üîó GitHub: https://github.com/schactye/ai-text-analyzer")

if __name__
